{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "%sql sqlite:///movies1.db\n",
    "result = %sql SELECT * FROM movies WHERE movie_id <100\n",
    "dataframe = result.DataFrame()\n",
    "dataframe.head()\n",
    "\n",
    "%%sql\n",
    "SELECT * \n",
    "FROM movies \n",
    "WHERE movie_id <100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "\n",
    "print(df.info()) #df datatype\n",
    "\n",
    "\n",
    "df.Gender.value_counts(dropna=False)\n",
    "[df[i].value_counts(dropna = False) for i in df.columns]\n",
    "\n",
    "\n",
    "df.describe() #descriptive stats\n",
    "\n",
    "\n",
    "df.shape #df shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change Datatype/Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MONTH'] = df['MONTH'].astype(str)\n",
    "\n",
    "\n",
    "y = y.astype(np.uint8)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(df, columns = col_name)\n",
    "\n",
    "\n",
    "#Converting Delay Time, which is our dependant numeric variable, to categorical variable, \"total_delay_bucket\" is a new col\n",
    "df.loc[(df['TOTAL_DELAY'] <= 30), 'total_delay_bucket'] = 0\n",
    "df.loc[(df['TOTAL_DELAY'] > 30), 'total_delay_bucket'] = 1\n",
    "df.loc[(df['TOTAL_DELAY'] > 30) & (df['AnnualGrossIncome'] <= 40), 'total_delay_bucket'] = 2\n",
    "\n",
    "\n",
    "#similarly, LE transform:\n",
    "from sklearn import preprocessing #这是把data的category转换成1234的label，给GaussianNB做\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_encoded = [le.fit_transform(df[i]) for i in df.columns]\n",
    "df_encoded = np.transpose(df_encoded)\n",
    "#transpose 是把numpy array 直角转90度，原来是行的数据变成列！\n",
    "col_name = df.columns.values\n",
    "df_encoded = pd.DataFrame(df_encoded, columns = col_name)\n",
    "\n",
    "\n",
    "#one hot encoding\n",
    "df_x = pd.get_dummies(df_x)\n",
    "\n",
    "\n",
    "#standardize column value between 0 and 1:\n",
    "A = df_resamplex['DISTANCE']\n",
    "df_resamplex['DISTANCE_Standardized'] = (A-min(A))/(max(A)-min(A))\n",
    "\n",
    "\n",
    "#change string data\n",
    "df['AnnualGrossIncome'].replace('[\\$,]', '', regex=True, inplace = True)\n",
    "#Regex for converting money value to numeric value\n",
    "df.AnnualGrossIncome = df.AnnualGrossIncome.astype(float, inplace= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change DF Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = np.transpose(df_encoded)\n",
    "\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4]) #adding dataframes together by row\n",
    "\n",
    "\n",
    "df = pd.merge()#Joining dataframes\n",
    "\n",
    "\n",
    "\n",
    "#MeltingData\n",
    "airquality_melt = pd.melt(airquality, id_vars=['Month', 'Day'], var_name='measurement', value_name='reading')\n",
    "#id_vars里面放的是你不想melt的column，value_cars = []里面可以放想要melt的column\n",
    "\n",
    "\n",
    "#Pivot Data\n",
    "airquality_pivot = airquality_melt.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading')\n",
    "#Pivot是反过来，把row里面的东西一个个变成column head\n",
    "#After Metling and pivoting you might want to use index_reset function because it will create a multi-index for the df\n",
    "\n",
    "#Pivot_table\n",
    "airquality_pivot = airquality_dup.pivot_table(index=['Month', 'Day'], columns='measurement', values='reading', aggfunc=np.mean)\n",
    "#This is used when there is duplicated values in rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop/Delete Rows/Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Droplist = ['Amer/Alaska&White','Amer/Alsk Native&Blk','Amer/Alaska Native']\n",
    "deletlist = df.loc[df['Race'].isin(iter(Droplist))]\n",
    "#这个很重要，可以drop所有有相应value的data\n",
    "df.drop(deletlist.index, inplace = True)\n",
    "\n",
    "#OR\n",
    "df = df[df['Race'] =! Droplist]\n",
    "\n",
    "\n",
    "#drop single column\n",
    "df.drop(['new'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#Can also drop rows\n",
    "df.drop('E',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data by 1.Columns 2.Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kinda like subsetting in R\n",
    "df_x = df[['MONTH', 'DAY_OF_WEEK', 'OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST',\n",
    "       'DEP_TIME_BLK', 'DISTANCE',]]\n",
    "\n",
    "\n",
    "# unequal signs works as well\n",
    "df0 = df[df['total_delay_bucket'] == 0]\n",
    "df1 = df[df['total_delay_bucket']==1]\n",
    "\n",
    "\n",
    "#sampling\n",
    "df0 = df0.sample(frac = 0.13, random_state = 5)\n",
    "#after sampling by class you might want to concat them back:\n",
    "df_resample = pd.concat([df0,df1])\n",
    "\n",
    "\n",
    "#select W,Z column based on Y column value\n",
    "df[df['Y']>0][['W','Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining/Merging/Grouping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is telling pandas to join two tables with 2columns being the same,也就是你的主键/客键在每个datatable里都有两列数据组合\n",
    "pd.merge(left, right, on=['key1', 'key2'])\n",
    "\n",
    "\n",
    "#normal join:\n",
    "df1.merge(df2, left_on='lkey', right_on='rkey')\n",
    "\n",
    "\n",
    "#groupby and calculation\n",
    "alldata.groupby('Race').mean().Age\n",
    "alldata.groupby('Race').Age.idxmax() #return individual max value for each group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
